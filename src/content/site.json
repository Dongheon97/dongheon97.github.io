{
  "hero": {
    "name": "Dongheon Lee",
    "role_title": "Autonomous Systems Research Engineer",
    "one_liner": "Master’s student working on UAV systems, multi-agent coordination, and end-to-end autonomous algorithms",
    "location": "West Lafayette, IN, U.S.A.",
    "profile_image": "images/profile.png",
    "links": {
      "email": "dongheon.lee97@gmail.com",
      "github": "https://github.com/Dongheon97",
      "linkedin": "https://linkedin.com/in/dongheon97",
      "cv_pdf": "pdf/DongheonLee_CV.pdf"
    }
  },
  "expertise": {
    "categories": [
      {
        "title": "Robotics & Autonomous Systems",
        "keywords": ["ROS 1/2", "PX4 Autopilot", "Gazebo", "Isaac Sim"],
        "highlight_line": "Building autonomous UAV systems from simulation to real-world deployment"
      },
      {
        "title": "Programming & Development",
        "keywords": ["C/C++", "Python", "Java", "MySQL", "CMake", "Bash", "Git", "Docker"],
        "highlight_line": "Developing robust software for robotics and embedded systems"
      },
      {
        "title": "Machine Learning",
        "keywords": ["TensorFlow", "PyTorch", "Object Detection", "Gaussian Splatting", "Reinforcement Learning", "Federated Learning"],
        "highlight_line": "Applying ML and CV to robotics and sensing applications"
      },
      {
        "title": "Hardware & Integration",
        "keywords": ["Pixhawk", "VOXL (ModalAI)", "STM32", "FPV Drones", "3D Printers", "Microhard", "DoodleLabs"],
        "highlight_line": "Integrating custom hardware for autonomous systems"
      }
    ]
  },
  "projects": [
    {
      "slug": "lidar-autonomy-evaluation",
      "title": "Evaluating Trade-offs Between LiDAR Specifications and Autonomy Performance",
      "one_liner": "Built a closed-loop autonomy evaluation framework to quantify how LiDAR specifications impact drone navigation and replanning performance",
      "tags": ["ROS 1/2", "Sensor Fusion", "LiDAR", "RRT", "Path Planning", "Collision Avoidance", "Simulation"],
      "timeframe": "Apr 2025 – Jul 2025",
      "role": "Software Engineer",
      "team": "Applied Intuition with Korean Tier-1 sensor supplier",
      "stack": ["ROS 1/2", "Python", "C++", "Gazebo", "Applied Intuition Simulation"],
      "problem": [
        "Different LiDAR configurations (range, FOV, angular resolution, noise) produced drastically different mapping quality and planner behavior, but their impact on autonomy was not quantitatively understood",
        "In-house simulation infrastructure only supported ROS 2, requiring migration of a legacy ROS 1-based 3D mapping and navigation stack",
        "Dense urban drone scenarios required frequent replanning and reliable collision avoidance",
        "Sensor vendors and autonomy teams lacked a principled way to compare LiDAR options for real-world deployment"
      ],
      "approach": [
        "Migrated a GPS-denied drone navigation stack from ROS 1 to ROS 2 on an in-house simulation platform",
        "Built a closed-loop autonomy evaluation pipeline connecting LiDAR simulation, mapping, RRT-based planning, collision checking, and replanning",
        "Parameterized LiDAR models in simulation to vary range, FOV, angular resolution, and noise characteristics",
        "Designed experimental protocols and evaluation pipelines measuring success rate, completion time, replanning frequency, and path efficiency across sensor configurations"
      ],
      "contributions": [
        "Designed and implemented a sensor-to-autonomy evaluation framework linking LiDAR specifications to navigation outcomes",
        "Identified critical LiDAR parameter regimes that directly affect planner stability and mission success",
        "Developed standardized autonomy metrics enabling objective comparison between sensor configurations",
        "Produced decision-grade analysis used by autonomy and hardware teams to evaluate LiDAR trade-offs"
      ],
      "results": [
        "Successfully migrated and validated a full ROS 1 autonomy stack on ROS 2 without loss of functionality",
        "Quantified how LiDAR range, FOV, and resolution influence replanning behavior, path efficiency, and failure rates",
        "Analysis directly supported proof-of-concept agreements between collaborating companies",
        "Established a reusable evaluation framework for future LiDAR and perception system benchmarking"
      ],
      "media": {
        "type": "youtube",
        "embed_url": "https://www.youtube.com/embed/OOjkADXE0zU",
        "description": "In-house simulation showing LiDAR point clouds (left) and a drone navigating a dense urban environment (right)."
      },
      "sub_media": {
        "type": "youtube",
        "embed_url": "https://www.youtube.com/embed/97EqxBJj24M",
        "description": "Engineering view of 3D mapping and path planning. The RGB-D map is built from fused LiDAR and camera data, while the green line shows the planned trajectory and waypoints. The system performs real-time collision checking and replanning for autonomous flight."
      },
      "links": {},
      "thumbnail": "projects/lidar_eval/poc_thumbnail.png"
    },
    {
      "slug": "multi-agent-uav-mesh-network",
      "title": "Multi-Agent UAV Systems with Mesh-Based Communication",
      "one_liner": "Designed and implemented a scalable multi-agent UAV system using mesh networking for robust real-time coordination",
      "tags": ["ROS 2", "PX4", "Multi-Agent Systems", "Mesh Networking", "Swarm Robotics", "Distributed Systems"],
      "timeframe": "May 2024 – Nov 2024",
      "role": "Software Engineer",
      "team": "EpiSci SwarmSense Team",
      "stack": ["ROS 2", "PX4", "VOXL", "Python", "C++", "Mesh Radios"],
      "problem": [
        "Multi-agent UAV systems require reliable communication to coordinate in dynamic and partially connected environments",
        "Network overhead and latency limited scalability as the number of UAVs increased",
        "Hardware-level mesh networking required custom integration with onboard computers and radios",
        "Swarm coordination depended on real-time exchange of network status, battery, and localization data"
      ],
      "approach": [
        "Designed a multi-agent UAV architecture with decentralized mesh-based communication between aerial and ground nodes",
        "Implemented lightweight serialization and JSON-RPC interfaces for efficient inter-agent messaging",
        "Integrated mesh radios with onboard computers using custom mounts and RF tuning",
        "Developed a swarm manager to aggregate and distribute real-time network, battery, and position data"
      ],
      "contributions": [
        "Designed and implemented a scalable mesh networking layer for multi-agent UAV coordination",
        "Reduced communication overhead by 50% through custom message serialization and protocol optimization",
        "Led hardware–software integration of mesh radios on UAV platforms"
      ],
      "results": [
        "Achieved reliable multi-agent coordination under intermittent and bandwidth-limited network conditions",
        "Demonstrated scalable swarm operation with significantly reduced communication overhead",
        "Validated mesh-based communication as a viable backbone for distributed UAV systems",
        "Enabled real-time sharing of critical agent states including network health, battery, and position"
      ],
      "media": {
        "type": "youtube",
        "embed_url": "https://youtube.com/embed/75kVha7HXeQ",
        "description": "Field test of a multi-agent UAV system with one user entity (lead UAV), one ground control station (GCS), and three relay UAVs. As the lead UAV moves out of direct communication range, relay drones autonomously take off and position themselves to form a mesh network that maintains connectivity between the UAV and the GCS. The GUI in the lower-left shows real-time network status, battery levels, and positions of all agents. UAVs automatically return to their launch point for battery replacement and rejoin the mission, demonstrating persistent and self-maintaining swarm operation."
      },
      "links": {},
      "thumbnail": "projects/swarm/mesh_network_thumbnail.png"
    },
    {
      "slug": "gps-denied-3d-mapping",
      "title": "GPS-Denied Indoor Navigation – NIST 5.0 3D Mapping Challenge",
      "one_liner": "Implemented advanced 3D mapping using Gaussian Splatting for GPS-denied environments",
      "tags": ["ROS 1", "Gaussian Splatting", "3D Mapping", "3D Object Detection", "VOXL", "PX4"],
      "timeframe": "Jun 2023 – Oct 2024",
      "role": "Software Engineer",
      "team": "EpiSci SwarmSense Team",
      "stack": ["ROS", "Gaussian Splatting", "Voxblox", "MeshLab", "VOXL-PX4", "Python"],
      "problem": [
        "GPS-denied indoor environments require accurate and consistent 3D world models for autonomous navigation",
        "Real-time SLAM and voxel mapping produced noisy and incomplete meshes in cluttered indoor scenes",
        "Autonomy teams and operators needed a higher-fidelity 3D representation for inspection, planning, and situational awareness",
        "Vision and LiDAR data needed to be fused into a single spatially consistent map"
      ],
      "approach": [
        "Built a perception-to-mapping pipeline combining VOXL-based visual–inertial odometry, LiDAR depth, and Voxblox voxel mapping",
        "Applied Gaussian Splatting to convert noisy voxel meshes into high-quality 3D reconstructions for evaluation and inspection",
        "Integrated ROS-based 3D object detection and overlaid detected objects directly on the 3D map",
        "Customized VOXL–PX4 firmware to improve VIO, depth alignment, and mapping stability in GPS-denied environments"
      ],
      "contributions": [
        "Designed and implemented a full perception and 3D mapping pipeline for indoor autonomous flight",
        "Significantly improved map fidelity using Gaussian Splatting on top of real-time voxel maps",
        "Integrated object detection into the 3D world model for autonomy and operator use",
        "Enhanced VOXL–PX4 sensor fusion for more stable localization in GPS-denied environments"
      ],
      "results": [
        "Reached the final stage of NIST 5.0 3D Mapping Challenge",
        "Produced high-fidelity 3D reconstructions of complex indoor environments from real UAV flight data",
        "Enabled reliable navigation and inspection in GPS-denied spaces using LiDAR–vision fused maps",
        "Delivered a 3D world model suitable for both autonomy algorithms and human operators"
      ],
      "media": {
        "type": "youtube",
        "embed_url": "https://youtube.com/embed/j0OiYkcyra4",
        "description": "Real-world flight demonstrating real-time 3D mapping and post-processed high-fidelity reconstruction. The top-left shows the UAV in flight, the bottom-left shows live 3D mapping, and the right shows the onboard camera stream. After the flight, recorded data is processed with Gaussian Splatting to rapidly generate a significantly higher-quality 3D map."
      },
      "links": {
        "project": "https://www.nist.gov/ctl/pscr/open-innovation-prize-challenges/past-prize-challenges/2023-first-responder-uas-3d-mapping",
        "team": "https://www.nist.gov/ctl/pscr/episci"
      },
      "thumbnail": "projects/gps-denied-indoor-nav/gdin_thumbnail.png"
    },
    {
      "slug": "automated-shot-group-measurement",
      "title": "Automated Shot Group Size Measuring System",
      "one_liner": "IEEE-published vision-based system for remote ballistic analysis with 91.8% accuracy",
      "tags": ["OpenCV", "YOLO", "Image Processing", "IoT", "Raspberry Pi", "LoRa"],
      "timeframe": "Dec 2021 – Aug 2022",
      "role": "Research Intern",
      "team": "Chungnam National University & Purdue University",
      "stack": ["Python", "OpenCV", "YOLOv3", "Raspberry Pi", "LoRa", "IoT Sensors"],
      "problem": [
        "Manual shot group measurement was time-consuming and error-prone",
        "Remote ballistic analysis required automated, contactless measurement",
        "Needed high accuracy for precision shooting analysis",
        "Integration of IoT components for remote data collection required"
      ],
      "approach": [
        "Led development of vision-based shot group measurement system",
        "Implemented bullet hole detection using OpenCV-based image warping and alignment",
        "Trained YOLOv3 models optimized for embedded inference",
        "Integrated IoT components including Raspberry Pi, sound sensors, cameras, and LoRa"
      ],
      "contributions": [
        "Led complete system development from concept to implementation",
        "Implemented image warping and alignment achieving 91.8% accuracy",
        "Trained and optimized YOLOv3 models for embedded deployment",
        "Integrated multi-modal IoT sensors for remote data collection"
      ],
      "results": [
        "Achieved 91.8% accuracy in shot group measurement",
        "Resulted in peer-reviewed publication at IEEE SAS 2022",
        "Enabled remote, contactless ballistic analysis",
        "Integrated complete IoT system for automated data collection"
      ],
      "media": {
        "type": "youtube",
        "embed_url": "https://youtube.com/embed/l6NRirrmg5o",
        "description": "dddd"
      },
      "links": {},
      "thumbnail": "projects/shot_tracker/shot_tracker.jpeg"
    }
  ],
  "publications": [
    {
      "title": "Feasibility of Measuring Shot Group Using LoRa Technology and YOLO V5",
      "authors": "Dongheon Lee, et al.",
      "venue": "IEEE Sensors Applications Symposium (SAS)",
      "year": "2022",
      "doi_url": "https://doi.org/10.1109/SAS54819.2022.9881356",
      "pdf_path": "pdf/SAS-2022.pdf"
    },
    {
      "title": "A Case Study on Scenario-Based Mobile Application UI Action Test",
      "authors": "Dongheon Lee, et al.",
      "venue": "Korean Institute of Information Scientists and Engineers (KIICE)",
      "year": "2021",
      "doi_url": "",
      "pdf_path": ""
    }
  ],
  "experience": [
    {
      "org": "Networked Control Systems Lab, Purdue University",
      "title": "Graduate Research Assistant",
      "start": "Sep 2025",
      "end": "Present",
      "location": "West Lafayette, IN, U.S.A.",
      "bullets": [
        "Developed MPPI- and MPC-based control frameworks for 4-channel fixed-wing UAV enabling aggressive pylon navigation",
        "Designed cost functions and tuning strategies, performing simulation-to-flight transfer with real-world flight validation",
        "Analyzed controller robustness and failure modes under wind and sensing uncertainty"
      ]
    },
    {
      "org": "Applied Intuition",
      "title": "Software Engineer",
      "start": "Nov 2024",
      "end": "Jul 2025",
      "location": "Seoul, South Korea",
      "bullets": [
        "Migrated EpiSci's 3D mapping stack from ROS 1 to ROS 2 within Applied Intuition's simulation platform",
        "Evaluated LiDAR specification trade-offs on drone autonomy performance with Tier-1 sensor supplier",
        "Delivered simulation training workshops for Korean automotive OEM and airline R&D center"
      ]
    },
    {
      "org": "EpiSci (Acquired by Applied Intuition)",
      "title": "Software Engineer",
      "start": "Oct 2023",
      "end": "Nov 2024",
      "location": "Seoul, South Korea",
      "bullets": [
        "Developed autonomous multi-agent UAV systems enabling efficient data exchange and swarm coordination",
        "Applied computer vision and machine learning techniques including 3D Gaussian Splatting for enhanced visualization",
        "Led sim-to-real deployment from Gazebo to real drones using ROS 2, PX4, and VOXL",
        "Demonstrated UAV applications to NIST, U.S. Army, and DARPA"
      ]
    },
    {
      "org": "EpiSci (Acquired by Applied Intuition)",
      "title": "Software Engineering Intern",
      "start": "Sep 2022",
      "end": "Sep 2023",
      "location": "Poway, CA, U.S.A.",
      "bullets": [
        "Evaluated visual-inertial odometry and obstacle avoidance algorithms on indoor drones using ROS 1",
        "Developed frontier-based exploration and object detection modules for PX4-based drones",
        "Built ATAK Android plugin for drone control and monitoring",
        "Earned FAA Part 107 certification"
      ]
    }
  ],
  "education": [
    {
      "school": "Purdue University",
      "degree": "M.S. in Electrical and Computer Engineering",
      "location": "West Lafayette, IN, U.S.A.",
      "start": "Aug 2025",
      "end": "Present",
      "bullets": [
        "GPA: 3.61 / 4.0",
        "Specializing in automatic control with interests in reinforcement learning, autonomous systems, and distributed robotics"
      ]
    },
    {
      "school": "Chungnam National University (CNU)",
      "degree": "B.E. in Computer Science and Engineering",
      "location": "Daejeon, South Korea",
      "start": "Mar 2017",
      "end": "Feb 2023",
      "bullets": [
        "GPA: 3.88 / 4.0 (3rd out of 102 students)",
        "Strong foundation in computer science and software engineering"
      ]
    }
  ],
  "awards": [
    {
      "name": "Student Engineer of the Year",
      "org": "College of Engineering, CNU",
      "year": "2022",
      "note": "Recognized for outstanding academic and research achievements"
    },
    {
      "name": "Sponsor's Award",
      "org": "2022 Software Talent Competition, IITP Korea",
      "year": "2022",
      "note": "Awarded by competition sponsor for excellence"
    },
    {
      "name": "Encouragement Award",
      "org": "KIICE Poster Session",
      "year": "2021",
      "note": "For poster presentation on mobile application testing"
    },
    {
      "name": "Full Scholarship",
      "org": "Department of CSE, CNU",
      "year": "4 semesters",
      "note": "Academic excellence award for 4 semesters"
    },
    {
      "name": "Full Scholarship",
      "org": "Sejong City Foundation",
      "year": "2020",
      "note": "Foundation scholarship for academic achievement"
    },
    {
      "name": "Partial Scholarship",
      "org": "Department of CSE, CNU",
      "year": "3 semesters",
      "note": "Academic excellence award for 3 semesters"
    }
  ]
}
