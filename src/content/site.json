{
  "hero": {
    "name": "Dongheon Lee",
    "role_title": "Autonomous Systems Research Engineer",
    "one_liner": "Master’s student working on UAV systems, multi-agent coordination, and end-to-end autonomous algorithms",
    "location": "West Lafayette, IN, U.S.A.",
    "profile_image": "images/profile.png",
    "links": {
      "email": "dongheon.lee97@gmail.com",
      "github": "https://github.com/Dongheon97",
      "linkedin": "https://linkedin.com/in/dongheon97",
      "cv_pdf": "pdf/DongheonLee_CV.pdf"
    }
  },
  "expertise": {
    "categories": [
      {
        "title": "Robotics & Autonomous Systems",
        "keywords": ["ROS 1/2", "PX4 Autopilot", "MAVLink", "QRB-5165", "Gazebo", "Isaac Sim", "OpenAI Gym"],
        "highlight_line": "Building autonomous UAV systems from simulation to real-world deployment"
      },
      {
        "title": "Programming & Development",
        "keywords": ["C/C++", "Python", "Java", "MySQL", "CMake", "Bash", "Git", "Docker"],
        "highlight_line": "Developing robust software for robotics and embedded systems"
      },
      {
        "title": "Machine Learning",
        "keywords": ["TensorFlow", "PyTorch", "Object Detection", "Gaussian Splatting", "Reinforcement Learning", "Federated Learning"],
        "highlight_line": "Applying ML and CV to robotics and sensing applications"
      },
      {
        "title": "Hardware & Integration",
        "keywords": ["Pixhawk", "VOXL (ModalAI)", "STM32", "FPV Drones", "3D Printers", "Microhard", "DoodleLabs"],
        "highlight_line": "Integrating custom hardware for autonomous systems"
      }
    ]
  },
  "projects": [
    {
      "slug": "lidar-autonomy-evaluation",
      "title": "Evaluating Trade-offs Between LiDAR Specifications and Autonomy Performance",
      "one_liner": "Built a closed-loop autonomy evaluation framework to quantify how LiDAR specifications impact drone navigation and replanning performance",
      "tags": ["ROS 1/2", "Sensor Fusion", "LiDAR", "RRT", "Path Planning", "Collision Avoidance", "Simulation"],
      "timeframe": "Apr 2025 – Jul 2025",
      "role": "Software Engineer",
      "team": "Applied Intuition with Korean Tier-1 sensor supplier",
      "stack": ["ROS 1/2", "Python", "C++", "Gazebo", "Applied Intuition Simulation"],
      "problem": [
        "Different LiDAR configurations (range, FOV, angular resolution, noise) produced drastically different mapping quality and planner behavior, but their impact on autonomy was not quantitatively understood",
        "In-house simulation infrastructure only supported ROS 2, requiring migration of a legacy ROS 1-based 3D mapping and navigation stack",
        "Dense urban drone scenarios required frequent replanning and reliable collision avoidance",
        "Sensor vendors and autonomy teams lacked a principled way to compare LiDAR options for real-world deployment"
      ],
      "approach": [
        "Migrated a GPS-denied drone navigation stack from ROS 1 to ROS 2 on an in-house simulation platform",
        "Built a closed-loop autonomy evaluation pipeline connecting LiDAR simulation, mapping, RRT-based planning, collision checking, and replanning",
        "Parameterized LiDAR models in simulation to vary range, FOV, angular resolution, and noise characteristics",
        "Designed experimental protocols and evaluation pipelines measuring success rate, completion time, replanning frequency, and path efficiency across sensor configurations"
      ],
      "contributions": [
        "Designed and implemented a sensor-to-autonomy evaluation framework linking LiDAR specifications to navigation outcomes",
        "Identified critical LiDAR parameter regimes that directly affect planner stability and mission success",
        "Developed standardized autonomy metrics enabling objective comparison between sensor configurations",
        "Produced decision-grade analysis used by autonomy and hardware teams to evaluate LiDAR trade-offs"
      ],
      "results": [
        "Successfully migrated and validated a full ROS 1 autonomy stack on ROS 2 without loss of functionality",
        "Quantified how LiDAR range, FOV, and resolution influence replanning behavior, path efficiency, and failure rates",
        "Analysis directly supported proof-of-concept agreements between collaborating companies",
        "Established a reusable evaluation framework for future LiDAR and perception system benchmarking"
      ],
        "media": {
          "description": "No public media available due to NDA. If you are interested in learning more about this project, please reach out to me directly."
        },
      "links": {},
      "thumbnail": "projects/lidar_eval/poc_thumbnail.png"
    },
    {
      "slug": "multi-agent-uav-mesh-network",
      "title": "Multi-Agent UAV Systems with Mesh-Based Communication",
      "one_liner": "Designed and implemented a scalable multi-agent UAV system using mesh networking for robust real-time coordination",
      "tags": ["ROS 2", "PX4", "Multi-Agent Systems", "Mesh Networking", "Swarm Robotics", "Distributed Systems"],
      "timeframe": "May 2024 – Nov 2024",
      "role": "Software Engineer",
      "team": "EpiSci SwarmSense Team",
      "stack": ["ROS 2", "PX4", "VOXL", "Python", "C++", "Mesh Radios"],
      "problem": [
        "Multi-agent UAV systems require reliable communication to coordinate in dynamic and partially connected environments",
        "Network overhead and latency limited scalability as the number of UAVs increased",
        "Hardware-level mesh networking required custom integration with onboard computers and radios",
        "Swarm coordination depended on real-time exchange of network status, battery, and localization data"
      ],
      "approach": [
        "Designed a multi-agent UAV architecture with decentralized mesh-based communication between aerial and ground nodes",
        "Implemented lightweight serialization and JSON-RPC interfaces for efficient inter-agent messaging",
        "Integrated mesh radios with onboard computers using custom mounts and RF tuning",
        "Developed a swarm manager to aggregate and distribute real-time network, battery, and position data"
      ],
      "contributions": [
        "Designed and implemented a scalable mesh networking layer for multi-agent UAV coordination",
        "Reduced communication overhead by 50% through custom message serialization and protocol optimization",
        "Led hardware–software integration of mesh radios on UAV platforms"
      ],
      "results": [
        "Achieved reliable multi-agent coordination under intermittent and bandwidth-limited network conditions",
        "Demonstrated scalable swarm operation with significantly reduced communication overhead",
        "Validated mesh-based communication as a viable backbone for distributed UAV systems",
        "Enabled real-time sharing of critical agent states including network health, battery, and position"
      ],
      "media": {
        "description": "No public media available due to NDA. If you are interested in learning more about this project, please reach out to me directly."
      },
      "links": {},
      "thumbnail": "projects/swarm/mesh_network_thumbnail.png"
    },
    {
      "slug": "gps-denied-3d-mapping",
      "title": "GPS-Denied Indoor Navigation – NIST 5.0 3D Mapping Challenge",
      "one_liner": "Implemented advanced 3D mapping using Gaussian Splatting for GPS-denied environments",
      "tags": ["ROS 1", "Gaussian Splatting", "3D Mapping", "3D Object Detection", "VOXL", "PX4"],
      "timeframe": "Jun 2023 – Oct 2024",
      "role": "Software Engineer",
      "team": "EpiSci SwarmSense Team",
      "stack": ["ROS", "Gaussian Splatting", "Voxblox", "MeshLab", "VOXL-PX4", "Python"],
      "problem": [
        "GPS-denied indoor environments require accurate and consistent 3D world models for autonomous navigation",
        "Real-time SLAM and voxel mapping produced noisy and incomplete meshes in cluttered indoor scenes",
        "Autonomy teams and operators needed a higher-fidelity 3D representation for inspection, planning, and situational awareness",
        "Vision and LiDAR data needed to be fused into a single spatially consistent map"
      ],
      "approach": [
        "Built a perception-to-mapping pipeline combining VOXL-based visual–inertial odometry, LiDAR depth, and Voxblox voxel mapping",
        "Applied Gaussian Splatting to convert noisy voxel meshes into high-quality 3D reconstructions for evaluation and inspection",
        "Integrated ROS-based 3D object detection and overlaid detected objects directly on the 3D map",
        "Customized VOXL–PX4 firmware to improve VIO, depth alignment, and mapping stability in GPS-denied environments"
      ],
      "contributions": [
        "Designed and implemented a full perception and 3D mapping pipeline for indoor autonomous flight",
        "Significantly improved map fidelity using Gaussian Splatting on top of real-time voxel maps",
        "Integrated object detection into the 3D world model for autonomy and operator use",
        "Enhanced VOXL–PX4 sensor fusion for more stable localization in GPS-denied environments"
      ],
      "results": [
        "Reached the final stage of NIST 5.0 3D Mapping Challenge",
        "Produced high-fidelity 3D reconstructions of complex indoor environments from real UAV flight data",
        "Enabled reliable navigation and inspection in GPS-denied spaces using LiDAR–vision fused maps",
        "Delivered a 3D world model suitable for both autonomy algorithms and human operators"
      ],
      "media": {
        "description": "No public media available due to NDA. If you are interested in learning more about this project, please reach out to me directly."
      },
      "links": {
        "project": "https://www.nist.gov/ctl/pscr/open-innovation-prize-challenges/past-prize-challenges/2023-first-responder-uas-3d-mapping",
        "team": "https://www.nist.gov/ctl/pscr/episci"
      },
      "thumbnail": "projects/gps-denied-indoor-nav/gdin_thumbnail.png"
    },
    {
      "slug": "beyondgrip-slip-recovery",
      "title": "BeyondGrip – Physics-Informed RL for Slip Recovery",
      "one_liner": "Team project on using physics-informed reinforcement learning to recover racecars from loss of tire grip",
      "tags": ["Reinforcement Learning", "Vehicle Dynamics", "Assetto Corsa", "SAC", "TD3"],
      "timeframe": "Fall 2025",
      "role": "Team Project",
      "team": "Purdue University",
      "stack": ["Python", "PyTorch", "Assetto Corsa Gym", "SAC", "TD3", "MPC"],
      "problem": [
        "Racecars frequently lose stability due to oversteer, understeer, and traction loss, requiring rapid corrective control",
        "Standard RL agents trained by trial-and-error struggle to recover from out-of-distribution slip conditions",
        "Purely data-driven policies lack physical awareness of tire grip, load transfer, and slip dynamics"
      ],
      "approach": [
        "Built a multi-phase control framework consisting of MPC-based speed-up, slip induction, and RL-based recovery",
        "Designed physics-informed reward functions using slip angle, slip ratio, wheel load, and steering dynamics",
        "Trained SAC and TD3 agents in targeted slip scenarios within the Assetto Corsa high-fidelity racing simulator"
      ],

      "contributions": [
        "Set up and documented the Assetto Corsa simulation environment and training pipeline",
        "Designed slip-induction and recovery scenarios with phase-based control handoff between MPC and RL",
        "Implemented training scripts coordinating launch, slip, and recovery phases",
        "Fine-tuned SAC and TD3 models for stable and fast slip recovery"
      ],

      "results": [
        "Physics-informed TD3 achieved significantly higher recovery success rates under out-of-distribution slip conditions",
        "Demonstrated faster and more stable recovery compared to standard SAC and TD3 baselines",
        "Showcased real-time recovery behavior in high-fidelity racing simulations"
      ],
      "media": {
        "type": "youtube",
        "embed_url": "https://youtube.com/embed/PF0iw8FWM3U",
        "description": "Demo in the Assetto Corsa simulator. The car is first accelerated using an MPC controller, a slip event is then induced, and an RL controller takes over to recover the vehicle back to a stable driving state."
      },
      "links": {
        "slides": "https://docs.google.com/presentation/d/1ce0av-2WN4mu0gjzh9y-z4s9mejARhAe47wh14bNHGg/edit?usp=sharing"
      },
      "thumbnail": "projects/slip_recovery/slip_recovery_thumbnail.png"
    },
    {
      "slug": "automated-shot-group-measurement",
      "title": "Automated Shot Group Measurement System",
      "one_liner": "IEEE-published vision-based system for remote and contactless shot group measurement with 91.8% accuracy",
      "tags": ["OpenCV", "YOLO", "Image Processing", "IoT", "Raspberry Pi", "LoRa"],
      "timeframe": "Dec 2021 – Aug 2022",
      "role": "Research Intern",
      "team": "Chungnam National University & Purdue University",
      "stack": ["Python", "OpenCV", "YOLOv3", "Raspberry Pi", "LoRa", "IoT Sensors"],

      "problem": [
        "Manual shot group measurement is slow, labor-intensive, and prone to human error",
        "Remote ballistic analysis requires automated and contactless data collection",
        "Precision shooting analysis demands high measurement accuracy",
        "Distributed sensors and communication are needed to support remote operation"
      ],

      "approach": [
        "Developed a vision-based system to detect and localize bullet holes on a target",
        "Applied image warping and alignment to compensate for camera perspective and target deformation",
        "Trained and optimized YOLOv3 models for bullet hole detection on embedded hardware",
        "Integrated Raspberry Pi, cameras, acoustic sensors, and LoRa for end-to-end data collection"
      ],

      "contributions": [
        "Designed and implemented the complete system from data acquisition to result reporting",
        "Implemented robust image alignment and warping to achieve 91.8% measurement accuracy",
        "Trained and deployed YOLOv3 models for real-time detection on embedded devices",
        "Integrated multi-modal IoT sensors for remote and contactless operation"
      ],

      "results": [
        "Achieved 91.8% accuracy in automated shot group measurement",
        "Resulted in a peer-reviewed publication at IEEE Sensors Applications Symposium (SAS 2022)",
        "Enabled remote and contactless ballistic analysis",
        "Delivered a fully integrated vision–IoT measurement system"
      ],
      "media": {
        "type": "youtube",
        "embed_url": "https://youtube.com/embed/l6NRirrmg5o",
        "description": "Demonstration of the full system using safe signal emulation. Bullet holes and gunshot events are simulated, while LoRa communication, Raspberry Pi–based object detection and image processing, and the Android app interface run exactly as they would in a real deployment. After each session, the system computes and displays shot group statistics for the user."
      },
      "links": {
      },
      "thumbnail": "projects/shot_tracker/shot_tracker.jpeg"
    }
  ],
  "experience": [
    {
      "org": "Networked Control Systems Lab, Purdue University",
      "title": "Graduate Research Assistant",
      "start": "Sep 2025",
      "end": "Present",
      "location": "West Lafayette, IN, U.S.A.",
      "bullets": [
        "Developed MPPI- and MPC-based control frameworks for 4-channel fixed-wing UAV enabling aggressive pylon navigation",
        "Designed cost functions and tuning strategies, performing simulation-to-flight transfer with real-world flight validation",
        "Analyzed controller robustness and failure modes under wind and sensing uncertainty"
      ]
    },
    {
      "org": "Applied Intuition",
      "title": "Software Engineer",
      "start": "Nov 2024",
      "end": "Jul 2025",
      "location": "Seoul, South Korea",
      "bullets": [
        "Migrated EpiSci's 3D mapping stack from ROS 1 to ROS 2 within Applied Intuition's simulation platform",
        "Evaluated LiDAR specification trade-offs on drone autonomy performance with Tier-1 sensor supplier",
        "Delivered simulation training workshops for Korean automotive OEM and airline R&D center"
      ]
    },
    {
      "org": "EpiSci (Acquired by Applied Intuition)",
      "title": "Software Engineer",
      "start": "Oct 2023",
      "end": "Nov 2024",
      "location": "Seoul, South Korea",
      "bullets": [
        "Developed autonomous multi-agent UAV systems enabling efficient data exchange and swarm coordination",
        "Applied computer vision and machine learning techniques including 3D Gaussian Splatting for enhanced visualization",
        "Led sim-to-real deployment from Gazebo to real drones using ROS 2, PX4, and VOXL",
        "Demonstrated UAV applications to NIST, U.S. Army, and DARPA"
      ]
    },
    {
      "org": "EpiSci (Acquired by Applied Intuition)",
      "title": "Software Engineering Intern",
      "start": "Sep 2022",
      "end": "Sep 2023",
      "location": "Poway, CA, U.S.A.",
      "bullets": [
        "Evaluated visual-inertial odometry and obstacle avoidance algorithms on indoor drones using ROS 1",
        "Developed frontier-based exploration and object detection modules for PX4-based drones",
        "Built ATAK Android plugin for drone control and monitoring",
        "Earned FAA Part 107 certification"
      ]
    }
  ],
  "education": [
    {
      "school": "Purdue University",
      "degree": "M.S. in Electrical and Computer Engineering",
      "location": "West Lafayette, IN, U.S.A.",
      "start": "Aug 2025",
      "end": "Present",
      "bullets": [
        "GPA: 3.61 / 4.0",
        "Specializing in automatic control with interests in reinforcement learning, autonomous systems, and distributed robotics"
      ]
    },
    {
      "school": "Chungnam National University (CNU)",
      "degree": "B.E. in Computer Science and Engineering",
      "location": "Daejeon, South Korea",
      "start": "Mar 2017",
      "end": "Feb 2023",
      "bullets": [
        "GPA: 3.88 / 4.0 (3rd out of 102 students)",
        "Strong foundation in computer science and software engineering"
      ]
    }
  ],
  "publications": [
    {
      "title": "Feasibility of Measuring Shot Group Using LoRa Technology and YOLO V5",
      "authors": "Dongheon Lee, et al.",
      "venue": "IEEE Sensors Applications Symposium (SAS)",
      "year": "2022",
      "doi_url": "https://doi.org/10.1109/SAS54819.2022.9881356",
      "pdf_path": "pdf/SAS-2022.pdf"
    },
    {
      "title": "A Case Study on Scenario-Based Mobile Application UI Action Test",
      "authors": "Dongheon Lee, et al.",
      "venue": "Korean Institute of Information Scientists and Engineers (KIICE)",
      "year": "2021",
      "doi_url": "",
      "pdf_path": ""
    }
  ],
  "awards": [
    {
      "name": "Engineer of the Year",
      "org": "Dean, College of Engineering, CNU",
      "year": "2022",
      "note": "Recognized for outstanding academic and research achievements"
    },
    {
      "name": "Sponsor's Award",
      "org": "2022 Software Talent Competition, IITP Korea",
      "year": "2022",
      "note": "Awarded by competition sponsor for excellence"
    },
    {
      "name": "Encouragement Award",
      "org": "KIICE Poster Session",
      "year": "2021",
      "note": "For poster presentation on mobile application testing"
    },
    {
      "name": "Full Scholarship",
      "org": "Sejong City Foundation",
      "year": "2020",
      "note": "Foundation scholarship for academic achievement"
    },
    {
      "name": "Full Scholarship",
      "org": "Department of CSE, CNU",
      "year": "4 semesters",
      "note": "Academic excellence award for 4 semesters"
    },
    {
      "name": "Partial Scholarship",
      "org": "Department of CSE, CNU",
      "year": "3 semesters",
      "note": "Academic excellence award for 3 semesters"
    }
  ]
}
